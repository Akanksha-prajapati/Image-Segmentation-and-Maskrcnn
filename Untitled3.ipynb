{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYDfKCdqOrIrpGsAzFHQrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akanksha-prajapati/Image-Segmentation-and-Maskrcnn/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUo6vcS_FXxS"
      },
      "outputs": [],
      "source": [
        "# Perform basic color-based segmentation to separate the blue color in an image:\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert to HSV color space\n",
        "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define the range for blue color in HSV\n",
        "lower_blue = np.array([100, 150, 0])\n",
        "upper_blue = np.array([140, 255, 255])\n",
        "\n",
        "# Create a mask for blue color\n",
        "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "\n",
        "# Bitwise the image and mask to extract blue objects\n",
        "blue_segment = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('Blue Segmentation', blue_segment)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#. Use edge detection with Canny to highlight object edges in an image:\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Canny edge detection\n",
        "edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('Edges', edges)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "kTGKP9M6FtMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Load a pretrained Mask R-CNN model from PyTorch and use it for object detection and segmentation on an image:\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load pretrained Mask R-CNN model\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread('image.jpg')\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Preprocess the image\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "image_tensor = transform(image_rgb).unsqueeze(0)\n",
        "\n",
        "# Perform object detection and segmentation\n",
        "with torch.no_grad():\n",
        "    prediction = model(image_tensor)\n",
        "\n",
        "# Extract the bounding boxes and masks\n",
        "boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "masks = prediction[0]['masks'].cpu().numpy()\n",
        "\n",
        "# Display the results\n",
        "for i in range(len(boxes)):\n",
        "    box = boxes[i]\n",
        "    mask = masks[i, 0]\n",
        "    mask = (mask > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
        "\n",
        "    # Overlay mask\n",
        "    image[mask == 255] = [0, 255, 0]\n",
        "\n",
        "# Show the result\n",
        "cv2.imshow('Mask R-CNN Segmentation', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "IDAUxNY0F4Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate bounding boxes for each object detected by Mask R-CNN in an image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "\n",
        "# Load pretrained Mask R-CNN model\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread('image.jpg')\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Preprocess the image\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "image_tensor = transform(image_rgb).unsqueeze(0)\n",
        "\n",
        "# Perform object detection\n",
        "with torch.no_grad():\n",
        "    prediction = model(image_tensor)\n",
        "\n",
        "# Extract bounding boxes\n",
        "boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "\n",
        "# Draw bounding boxes on the image\n",
        "for box in boxes:\n",
        "    x1, y1, x2, y2 = box\n",
        "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "\n",
        "# Show the result\n",
        "cv2.imshow('Bounding Boxes', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "r5WMfv2RGEiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert an image to grayscale and apply Otsu's thresholding method for segmentation:\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Otsu's thresholding\n",
        "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('Otsu Thresholding', thresh)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "RV3v2ecdGaCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Perform contour detection in an image to detect distinct objects or shapes:\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to reduce noise\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Perform edge detection\n",
        "edges = cv2.Canny(blurred, 100, 200)\n",
        "\n",
        "# Find contours in the edges image\n",
        "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Draw contours on the image\n",
        "cv2.drawContours(image, contours, -1, (0, 255, 0), 3)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('Contours', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "5Xs_1-0oGkJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply Mask R-CNN to detect objects and their segmentation masks in a custom image and display them:\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load pretrained Mask R-CNN model\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread('image.jpg')\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Preprocess the image\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "image_tensor = transform(image_rgb).unsqueeze(0)\n",
        "\n",
        "# Perform object detection and segmentation\n",
        "with torch.no_grad():\n",
        "    prediction = model(image_tensor)\n",
        "\n",
        "# Extract the bounding boxes and masks\n",
        "boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "masks = prediction[0]['masks'].cpu().numpy()\n",
        "\n",
        "# Display the results\n",
        "for i in range(len(boxes)):\n",
        "    box = boxes[i]\n",
        "    mask = masks[i, 0]\n",
        "    mask = (mask > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
        "\n",
        "    # Overlay mask\n",
        "    image[mask == 255] = [0, 255, 0]\n",
        "\n",
        "# Show the result\n",
        "cv2.imshow('Mask R-CNN Segmentation', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "nXUEUWUqGvnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply k-means clustering for segmenting regions in an image:\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread('image.jpg')\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Reshape the image to a 2D array of pixels\n",
        "pixels = image_rgb.reshape((-1, 3))\n",
        "\n",
        "# Convert to float32 for k-means\n",
        "pixels = np.float32(pixels)\n",
        "\n",
        "# Define criteria and apply kmeans\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
        "k = 4  # Number of clusters (colors)\n",
        "_, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "# Convert centers to uint8\n",
        "centers = np.uint8(centers)\n",
        "\n",
        "# Map the labels to the centers\n",
        "segmented_image = centers[labels.flatten()]\n",
        "\n",
        "# Reshape back to the original image shape\n",
        "segmented_image = segmented_image.reshape(image_rgb.shape)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('K-means Segmentation', segmented_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "mgAIANXWG7Z8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}